plot_ly(x = time(Dif_ord_PIB), y = Dif_ord_PIB, type = 'scatter', mode = 'lines', color = I("red"), name = "SerieDifOrd") %>%
add_trace(y = Dif_ord_PIB-Modelo_serie_diff_models$Fourier1DesempleoDiff, mode = 'lines', line = list(color = 'blue'), name = "Fourier1") %>%
add_trace(y = Dif_ord_PIB-Modelo_serie_diff_models$Fourier2DesempleoDiff, mode = 'lines', line = list(color = 'green'), name = "Fourier2") %>%
add_trace(y = Dif_ord_PIB-Modelo_serie_diff_models$DummyDesempleoDiff, mode = 'lines', line = list(color = 'purple'), name = "Dummy") %>%
layout(title = 'Tasa de Desempleo sin tendencia y estacionalidad (Diferencia Ordinaria, lag=1)',
xaxis = list(title = 'Mes', rangeslider = list(type = 'date')))
Train=ts(PIB3TS[1:61], start = c(2005, 1),frequency = 4)
Test=ts(PIB3TS[62:76],start=c(2020,2),frequency = 4)
h=1
lserie=length(PIB3TS)
ntrain=trunc(length(PIB3TS)*0.80)+1 ##% del datos en el conjunto de entrenamiento es del 80%.
ntrain
time(PIB3TS)
time(PIB3TS)[ntrain]###Me entrega la ultima fecha de la posición ntrain #Partiendo la serie en entrenamiento y test
train=window(PIB3TS,end=time(PIB3TS)[ntrain])
test=window(PIB3TS,start=time(PIB3TS)[ntrain]+1/4) ##1/4 porque es la fracción que corresponde a un trimestre
length(train)
ntest=length(test)
ntest ##Me define el valor de origins, o de ventanas de rolling.
lserie ### Comparar los valores
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante ### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval=cbind(test[1:ntest]) # Predicción un paso adelante
####Ajuste del modelo con los datos de entrenamiento
HWAP_train=stats::HoltWinters(train,gamma = 0)
HWAP_train$alpha
HWAP_train$beta ###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores. # por ejemplo como sigue:
require(utils)
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta) ##Grilla de Valores
####Se crean las ventanas de rolling y se obtiene los h-pronósticos para cada ventana(hay ntest posibles ventanas)
for(i in 1:(ntest)){x=window(PIB3TS,end=time(PIB3TS)[ntrain]+(i-1)/4)
print(length(x))
refit=stats::HoltWinters(x,gamma=0,alpha=HWAP_train$alpha,bet=HWAP_train$beta)
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) }
fchstepahe
errores_pred=verval -fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario.
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM).
RECM=sqrt(ECM) ##Se le saca raíz
#RECM ##se lee: Primera fila RECM 1-paso adelante y así sucesivamente.
ECM
plot_ly(x = time(test), y = test, type = 'scatter', mode = 'lines', color = I("red"), name = "PIB") %>%
add_trace(y = fchstepahe, mode = 'lines', line = list(color = 'blue'), name = "Predicciones") %>%
layout(title = 'PIB vs Predicciones (Abril 2020-Diciembre 2023)',          xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
library(forecast)
library(greybox)
HWAP_train=stats::HoltWinters(train,gamma=0)
h=1
ourCallETS <- "forecast::forecast(stats::HoltWinters(x=data,alpha=HWAP_train$alpha,beta=HWAP_train$beta,gamma=0),h=h)" ###Note que x=data es solo un argumento indeterminado.
ourValueETS <- c("mean","lower","upper")
origins=ntest   ##número de rolling windows
Valoresretornados1 <- ro(PIB3TS, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE)
t(Valoresretornados1$holdout)## Permiten verificar los verdaderos valores h-pasos adelante.
t(Valoresretornados1$mean)
apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE) ### Se calcula el error cuadrático medio de predicción
apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE) == ECM
#'c': Se ajusta una constante (serie estacionaria alrededor de una media constante).
#'ct': Se ajusta una constante y una tendencia lineal (serie estacionaria alrededor de una tendencia lineal).
#'nc': No se ajusta ni constante ni tendencia (serie estacionaria sin media constante ni tendencia).
#lremesas porque tocó hacer transformación boxcox
#Prueba Dickey-Fuller
#Hipótesis nula (H0): La serie tiene una raíz unitaria (no es estacionaria).
#Hipótesis alternativa (H1): La serie no tiene una raíz unitaria (es estacionaria).
ar(PIB3TS)
fUnitRoots::adfTest(PIB3TS,lags = 4,type='nc')
#P-valor = 0.99, lo que indica presencia de raíz unitaria, por lo que toca hacer diferenciación
diff_PIB <- diff(PIB3TS)
#El número de retardos debe cambiar en cada transformación o dejamos siempre los del original
fUnitRoots::adfTest(diff_PIB,lags = 4,type='nc')
#p-valor = 0.01, con la transformación la serie ya es estacionaria
##Autocorrelogramas
acf(diff_PIB)
acf(diff_PIB,lag.max = 10, ci.type='ma')# q=0,1, Q=0,1
pacf(diff_PIB,lag.max = 10) # p=0,1,2,...,9,10 P=0,1
#En resumen podríamos proponer max q=1, Q=1, p=10, P=1
#Cuando se diferencia 2 veces o más, en este caso dos ordinarias y una estacional, el drift se debería ignorar
diff_PIB_train <- window(diff_PIB,end = c(2020,1))
diff_PIB_test <- window(diff_PIB, start=c(2020,2), end=c(2023,4))
tictoc::tic()
modelo_automatico<-auto.arima(diff_PIB_train,d=1,D=0,max.p=0,max.q=4,max.P=0,max.Q=0,start.p=0, start.q=0,seasonal=FALSE,max.order=10,stationary=TRUE,ic="aic",stepwise=FALSE,allowmean = TRUE)
modelo_automatico
tictoc::toc()
ts_train_PIB <- window(PIB3TS,end = c(2020,1))
ts_test_PIB <- window(PIB3TS, start=c(2020,2), end=c(2023,4))
modelo_ajustado<-forecast::Arima(ts_train_PIB,order = c(0,1,4),lambda = LambdaPIB,include.constant = TRUE) ## ajustar según lo que digan las funciones de arriba
summary(modelo_ajustado)
coeftest(modelo_ajustado)
modelo_ajustado<-forecast::Arima(ts_train_PIB,order = c(0,1,4), lambda = LambdaPIB,include.constant = TRUE, fixed = c(0,0,0,0,NA))  ## eliminar los parametros no significativos
summary(modelo_ajustado)
coeftest(modelo_ajustado)
residuales=modelo_ajustado$residuals
plot(residuales)
#plot(SDresiduales)
acf(residuales,lag.max = 10)
pacf(residuales)
#Test de normalidad
#La hipótesis nula H0 es que los datos siguen una distribución normal.
#La hipótesis alternativa H1 es que los datos no siguen una distribución normal.
jarque.bera.test(residuales)
#P-valor de 0.000000346, por lo tanto los datos no siguen una distribución normal
#Test de autocorrelación
#Lags empiricamente se calcula como la raiz cuadrada del tamaño de muestra o si hay estacionalidad, se ingresa el periodo estacional, digamos en una mensual con estacionalidad anual colocamos 12 lags
#fitdf es la cantidad de parametros estimados en el modelo ARIMA (incluyendo el fidth(constante)), en este caso solo 2.
Box.test(residuales, lag = ceiling(sqrt(length(residuales))) , type = "Ljung-Box", fitdf = 1)
#H0:Los residuos son independientes y no están autocorrelacionados (es decir, la serie temporal ajustada es adecuada).
#H1: Los residuos presentan autocorrelación, lo que sugiere que el modelo no captura toda la estructura temporal de los datos.
#P-valor 0.7482, por lo tanto los residuos son independientes y no estan autocorrelocionados
monthplot(residuales)
spectrum(residuales,spans = c(3,5)) #3 menos suavizado que 5
###Estadisticas CUSUM
res=residuales
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estadistica cusum (valor común usado)
co=0.14013####Valor del cuantil aproximado para cusumsq para n/2 (valor común usado)
LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")
#CUSUMSQ
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")
lines(LQS,type="S",col="red")
lines(LQI,type="S",col="red")
#####Fase de Pronósticos
#h la cantidad de periodos adelante que desea pronosticar
pronosticos_PIB=forecast::forecast(modelo_ajustado,h=1,level=0.95)
plot(pronosticos_PIB)
h=1
lserie=length(PIB3TS)
ntrain=trunc(length(PIB3TS)*0.80+1)
ntrain
time(PIB3TS)
time(PIB3TS)[ntrain]###Me entrega la ultima fecha de la posicion ntrain
train=window(PIB3TS,end=c(2020,1))
test=window(PIB3TS,start=c(2020,2))
length(train)
ntest=length(test)
ntest
fcmat=matrix(0,nrow=ntest,ncol=h)
for(i in 1:ntest)
{
x=window(PIB3TS,end=c(2020,2)+(i-1)/4)
print(length(x))
refit=forecast::Arima(x,order = c(0,1,4),lambda = LambdaPIB,include.constant = TRUE, fixed = c(0,0,0,0,NA))
fcmat[i,]=test[i]-forecast(refit,h=h)$mean
}
fcmat
ECM=mean(fcmat^2)
ECM
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::#
#             App - proyecto series de tiempo                #
#             Desarrollado por: Juan Duitama                 #
#                          2024-1                            #
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::#
rm(list =ls())
# Librerías ---------------------------------------------------------------
library(shiny)
library(bslib)
library(bsicons)
library(shinyWidgets)
library(shinydashboard)
library(leaflet)
library(tidyverse)
library(readxl)
library(zoo)
library(dplyr)
library(lubridate)
library(plotly)
library(ggsci)
library(scales)
library(viridis)
library(plotly)
library(forecast)
library(MASS)
library(tidyverse)
library(lubridate)
library(timetk)
library(tibble)
library(zoo)
library(tsibble)
library(feasts)
library(fable)
library(cowplot)
library(astsa)
library(TSstudio)
library(fabletools)
library(TSA)
library(parsnip)
library(rsample)
library(modeltime)
library(tidymodels)
library(lmtest)
library(tseries)
library(urca)
library(uroot)
library(fUnitRoots)
library(aTSA)
library(sarima)
library(tsoutliers)
library(fpp)
library(here)
library(DT)
#Ruta<-setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#Ruta<- here::here()
Ruta<-"D:/Estadística/Semestres/Semestre 9/Series de Tiempo Univariadas/Shiny"
setwd(Ruta)
# Desempleo ---------------------------------------------------------------
Desempleo <- read_excel(paste0(Ruta,"/Datos/Desempleo.xlsx"), skip = 5, n_max = 276)
Desempleo <- subset(Desempleo, select = -`Tasa de ocupación (%)`)
colnames(Desempleo)<-c("AnioMes","TasaDesempleo")
Desempleo$AnioMes<-paste0(Desempleo$AnioMes,"-01")
Desempleo$AnioMes<-as.Date(Desempleo$AnioMes,format = "%Y-%m-%d")
#Objeto ts
DesempleoTS <- ts(rev(Desempleo$TasaDesempleo), start = c(2001, 1), end = c(2023, 12), frequency = 12)
DiferenciaOrd<-diff(DesempleoTS)
DiferTSibl<-as_tsibble(DiferenciaOrd)
#Estimación de la estacionalidad
ajuste_final_models<-DiferTSibl%>%model(
`Fourier1DesempleoDiff`=ARIMA(value~fourier(K=1)+pdq(0, 0, 0) + PDQ(0, 0, 0)),#1 componente de Fourier
`Fourier2DesempleoDiff`=ARIMA(value~fourier(K=2)+pdq(0, 0, 0) + PDQ(0, 0, 0)),#2 componente de Fourier
`Fourier3DesempleoDiff`=ARIMA(value~fourier(K=3)+pdq(0, 0, 0) + PDQ(0, 0, 0)),#3 componente de Fourier
`Fourier4DesempleoDiff`=ARIMA(value~fourier(K=4)+pdq(0, 0, 0) + PDQ(0, 0, 0)),#4 componente de Fourier
`DummyDesempleoDiff`=ARIMA(value~season()+pdq(0, 0, 0) + PDQ(0, 0, 0))#Ajuste dummy
)
glance(ajuste_final_models)
Modelo_serie_diff_models<-DiferTSibl%>%left_join(fitted(ajuste_final_models)|>group_by(.model)%>%
pivot_wider(names_from = .model, values_from = .fitted))
### Suavizamiento exponencial -----------------------------------------------
Train=ts(DesempleoTS[1:221], start = c(2001, 1),frequency = 12)
Test=ts(DesempleoTS[222:276],start=c(2019,6),frequency = 12)
h=1
lserie=length(DesempleoTS)
ntrain=trunc(length(DesempleoTS)*0.80)+1 ##% del datos en el conjunto de entrenamiento es del 80%.
ntrain
time(DesempleoTS)
time(DesempleoTS)[ntrain]###Me entrega la ultima fecha de la posición ntrain
#Partiendo la serie en entrenamiento y test
train=window(DesempleoTS,end=time(DesempleoTS)[ntrain])
test=window(DesempleoTS,start=time(DesempleoTS)[ntrain]+1/12)##1/12 porque es la fracción que corresponde a un mes
length(train)
ntest=length(test)
ntest ##Me define el valor de origins, o de ventanas de rolling.
lserie ### Comparar los valores
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante
### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval=cbind(test[1:ntest])
###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores.
# por ejemplo como sigue:
require(utils)
### ARMA --------------------------------------------------------------------
DesempNSDiff <- DiferenciaOrd-Modelo_serie_diff_models$DummyDesempleoDiff
ARPURODesem=Arima(DesempNSDiff,order=c(1,0,0),include.mean = FALSE)
Arima_automatico_desempleo=forecast::auto.arima(DesempNSDiff,d=0,D=0,max.p=5,max.q=5,start.p=0, start.q=0,seasonal=FALSE,max.order=10,stationary=TRUE,ic="bic",stepwise=FALSE,allowmean = TRUE)
# Análisis de residuales
residualesARPURO=ARPURODesem$residuals
###Estad?sticas CUSUM
resARPURO=residualesARPURO
cum=cumsum(resARPURO)/sd(resARPURO)
N=length(resARPURO)
cumq=cumsum(resARPURO^2)/sum(resARPURO^2)
Af=0.948 ###Cuantil del 95% para la estad?stica cusum
co=0.09821####Valor del cuantil aproximado para cusumsq para n/2 aprox 130
LS=Af*sqrt(N)+2*Af*c(1:length(resARPURO))/sqrt(N)
LI=-LS
LQS=co+(1:length(resARPURO))/N
LQI=-co+(1:length(resARPURO))/N
### ARIMA -------------------------------------------------------------------
#####Ajuste del Modelo
####Note que entramos la serie original
AjusteArima151=forecast::Arima(DesempleoTS,order = c(15,1,1),lambda = 1)
AjusteArimaRef=forecast::Arima(DesempleoTS,order = c(15,1,1),lambda = 1, fixed=c(NA,NA,NA,NA,NA,0,0,NA,0,NA,NA,NA,NA,0,NA,NA))
residualesARIMA=AjusteArimaRef$residuals
###Estad?sticas CUSUM
resARIMA=residualesARIMA
cum2=cumsum(resARIMA)/sd(resARIMA)
N2=length(resARIMA)
cumq2=cumsum(resARIMA^2)/sum(resARIMA^2)
Af=0.948 ###Cuantil del 95% para la estad?stica cusum
co=0.09821
LS2=Af*sqrt(N2)+2*Af*c(1:length(resARIMA))/sqrt(N2)
LI2=-LS2
LQS2=co+(1:length(resARIMA))/N2
LQI2=-co+(1:length(resARIMA))/N2
#####Fase de Pronósticos
pronosticos151=forecast::forecast(AjusteArimaRef,h=12,level=0.95)
## SARIMA ------------------------------------------------------------------
DdDesempleoTS=diff(DiferenciaOrd,lag=12)
modeloSARIMA = Arima(DesempleoTS, c(0, 1, 0),seasonal = list(order = c(5, 1, 1), period = 12),lambda = 1)
residualesSARIMA <- modeloSARIMA$residuals
###Estad?ticas CUSUM
resSARIMA=residualesSARIMA
cum3=cumsum(resSARIMA)/sd(resSARIMA)
N3=length(resSARIMA)
cumq3=cumsum(resSARIMA^2)/sum(resSARIMA^2)
Af3=0.948 ###Cuantil del 95% para la estad?stica cusum
co3=0.09821####Valor del cuantil aproximado para cusumsq para 140
LS3=Af3*sqrt(N3)+2*Af3*c(1:length(resSARIMA))/sqrt(N3)
LI3=-LS3
LQS3=co3+(1:length(resSARIMA))/N3
LQI3=-co3+(1:length(resSARIMA))/N3
#SARIMA (1,1,2)(2,1,1) en el conjunto de entrenamiento
trainSAR = window(DesempleoTS,end=time(DesempleoTS)[ntrain])
testSAR = window(DesempleoTS,start=time(DesempleoTS)[ntrain]+1/12)
SARIMAtrain = Arima(trainSAR, c(1, 1, 2),seasonal = list(order = c(2, 1, 1), period = 12),lambda = 1)
resSARIMAtrain <- SARIMAtrain$residuals
coeftrainSAR=coefs2poly(SARIMAtrain)
outliersSAR= tsoutliers::locate.outliers(resSARIMAtrain,coeftrainSAR)
outliersSAR###tstat se compara con C=3
xregtrainSAR = outliers.effects(outliersSAR, ntrain)
SARIMAtrain_out = update(SARIMAtrain, xreg = xregtrainSAR)
#Rolling
#SARIMAtrain_out
#refit <- Arima(DesempleoTS, model=fitmodelo)
#fc <- window(fitted(SARIMA_out), start=c(2019,6))
esta_param_modelo<-coef(SARIMAtrain_out)
h <- 1
nx <- length(test) - h + 1
xregtestSAR = cbind(matrix(0,nx,2),matrix(1,nx,4),matrix(0,nx,1))
xregro <- rbind(xregtrainSAR,xregtestSAR)
fitmodelox <- update(SARIMAtrain_out,fixed=esta_param_modelo)
fcx <- ts(numeric(nx), start=c(2019,6), freq=12)
for(i in 1:nx){
x <- window(DesempleoTS, end=c(2019, 5+(i-1)))
refit <- forecast::Arima(x, model=fitmodelox, xreg = xregro[1:(221+(i-1)),])
fcx[i] <- forecast::forecast(refit, h=h,xreg = t(as.matrix(xregro[(221+i),])))$mean[h]
}
difex=(test-fcx)^2
ecm=(1/(length(test)))*sum(difex)
ecm
#SARIMA definitivo con outliers en todo el conjunto de datos
modeloSARIMAdef = Arima(DesempleoTS, c(1, 1, 2),seasonal = list(order = c(2, 1, 1), period = 12),lambda = 1)
resSARIMAdef <- modeloSARIMAdef$residuals
n=length(DesempleoTS)
coef=coefs2poly(modeloSARIMAdef)
#coef
outliers= tsoutliers::locate.outliers(resSARIMAdef,coef)
###tstat se compara con C=3
xreg = outliers.effects(outliers, n)
SARIMA_out = update(modeloSARIMAdef, xreg = xreg)
#Ahora sí los propios residuales
residuales_propios <- SARIMA_out$residuals
###Estad?ticas CUSUM
res4=residuales_propios
cum4=cumsum(res4)/sd(res4)
N4=length(res4)
cumq4=cumsum(res4^2)/sum(res4^2)
Af4=0.948 ###Cuantil del 95% para la estad?stica cusum
co4=0.09821####Valor del cuantil aproximado para cusumsq para 140
LS4=Af4*sqrt(N4)+2*Af4*c(1:length(res4))/sqrt(N4)
LI4=-LS4
LQS4=co4+(1:length(res4))/N4
LQI4=-co4+(1:length(res4))/N4
#Rolling
#SARIMA_out
#refit <- Arima(DesempleoTS, model=fitmodelo)
fc <- window(fitted(SARIMA_out), start=c(2019,6))
esta_param_modelo<-coef(SARIMA_out)
h <- 1
train = window(DesempleoTS,end=time(DesempleoTS)[ntrain])
test = window(DesempleoTS,start=time(DesempleoTS)[ntrain]+1/12)
n <- length(test) - h + 1
fitmodelo <- update(SARIMA_out,fixed=esta_param_modelo)
fc <- ts(numeric(n), start=c(2019,6), freq=12)
for(i in 1:n)
{
x <- window(DesempleoTS, end=c(2019, 5+(i-1)))
refit <- forecast::Arima(x, model=fitmodelo, xreg = xreg[1:(221+(i-1)),])
fc[i] <- forecast::forecast(refit, h=h,xreg = t(as.matrix(xreg[(221+i),])))$mean[h]
}
dife=(test-fc)^2
ecm=(1/(length(test)))*sum(dife)
#Precciones de 2024
newdata <- read_excel("D:/Estadística/Semestres/Semestre 9/Series de Tiempo Univariadas/Datos/anex-GEIH-jul2024.xlsx", sheet = "Total nacional", range = "JR17:JX17",col_names = F)
newdata <- as.data.frame(t(newdata[1,]))
newdataTS <- ts((newdata), start = c(2024, 1), end = c(2024, 7), frequency = 12)
SARIMA_out
#refit <- Arima(DesempleoTS, model=fitmodelo)
#fc <- window(fitted(SARIMA_out), start=c(2019,6))
esta_param_modelosipo<-coef(SARIMA_out)
h <- 1
trainsuperxd = DesempleoTS
testsuperxd = newdataTS
nnu <- length(testsuperxd) - h + 1
fitmodelonu <- update(SARIMA_out,fixed=esta_param_modelosipo)
fcsuperxd <- ts(numeric(nnu), start=c(2024,1), freq=12)
xregtempx = cbind(matrix(0,nnu,5),matrix(1,nnu,4),matrix(0,nnu,2))
xregnew <- rbind(xreg,xregtempx)
DesempTSnew <- ts(c(DesempleoTS, newdataTS), start = start(DesempleoTS), frequency = 12)
for(i in 1:nnu){
x <- window(DesempTSnew, end=c(2023, 12+(i-1)))
refitnu <- forecast::Arima(x, model=fitmodelonu, xreg = xregnew[1:(276+(i-1)),])
fcsuperxd[i] <- forecast::forecast(refitnu, h=h,xreg = t(as.matrix(xregnew[277,])))$mean[h]
}
difenu=(testsuperxd-fcsuperxd)^2
ecmhola=(1/(length(testsuperxd)))*sum(difenu)
ecmhola
#ecm
MSE_Desempleo <- data.frame(
Modelo = c("SARIMA", "Suavizamiento exponencial", "Árboles", "Red multicapa", "Red GRU"),
MSE = c(6.731634, 3.75, 10.74, 6.55, 12.44)
)
# PIB ---------------------------------------------------------------------
PIB3 <- read_excel(paste0(Ruta,"/Datos/PIB.xlsx"), range = "AS18:AS93", col_names = FALSE)
PIB3 <- data.frame('Fecha'=seq.Date(from=as.Date("2005-03-01"),to=as.Date("2023-12-01"),by="quarter"),'PIBtrimestral'=PIB3$...1)
#Objeto ts
PIB3TS <- ts(PIB3$PIBtrimestral, start = c(2005, 1), end = c(2023, 4), frequency = 4)
LambdaPIB<-BoxCox.lambda(PIB3TS, method ="loglik", lower = -3, upper = 3)
Dif_ord_PIB<-diff(PIB3TS)
fitLMPIB <- lm(PIB3TS~time(PIB3TS), na.action=NULL)
## Suavizamiento Exponencial -----------------------------------------------
h2=1
lserie2=length(PIB3TS)
ntrain2=trunc(length(PIB3TS)*0.80)+1 ##% del datos en el conjunto de entrenamiento es del 80%.
ntrain
time(PIB3TS)
time(PIB3TS)[ntrain2]###Me entrega la ultima fecha de la posición ntrain #Partiendo la serie en entrenamiento y test
train2=window(PIB3TS,end=time(PIB3TS)[ntrain2])
test2=window(PIB3TS,start=time(PIB3TS)[ntrain2]+1/4) ##1/4 porque es la fracción que corresponde a un trimestre
ntest2=length(test2)
fchstepahe2=matrix(0,nrow=ntest2,ncol=h2) ##Crea una Columna para los h-pasos adelante ### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval2=cbind(test2[1:ntest2]) # Predicción un paso adelante
####Ajuste del modelo con los datos de entrenamiento
HWAP_train2=stats::HoltWinters(train2,gamma = 0)
HWAP_train2$alpha
HWAP_train2$beta ###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores. # por ejemplo como sigue:
require(utils)
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta) ##Grilla de Valores
####Se crean las ventanas de rolling y se obtiene los h-pronósticos para cada ventana(hay ntest posibles ventanas)
for(i in 1:(ntest2)){x=window(PIB3TS,end=time(PIB3TS)[ntrain2]+(i-1)/4)
refit2=stats::HoltWinters(x,gamma=0,alpha=HWAP_train2$alpha,bet=HWAP_train2$beta)
fchstepahe2[i,]=as.numeric(forecast::forecast(refit2,h=h2)$mean) }
errores_pred2=verval2 -fchstepahe2 ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario.
ECM=apply(errores_pred2^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM).
RECM=sqrt(ECM) ##Se le saca raíz
#RECM ##se lee: Primera fila RECM 1-paso adelante y así sucesivamente.
ECM
diff_PIB <- diff(PIB3TS)
# p=0,1,2,...,9,10 P=0,1
#En resumen podríamos proponer max q=1, Q=1, p=10, P=1
#Cuando se diferencia 2 veces o más, en este caso dos ordinarias y una estacional, el drift se debería ignorar
diff_PIB_train <- window(diff_PIB,end = c(2020,1))
diff_PIB_test <- window(diff_PIB, start=c(2020,2), end=c(2023,4))
## ARIMA -------------------------------------------------------------------
# tictoc::tic()
# modelo_automatico<-auto.arima(diff_PIB_train,d=1,D=0,max.p=0,max.q=4,max.P=4,max.Q=4,start.p=0, start.q=0,seasonal=FALSE,max.order=10,stationary=TRUE,ic="aic",stepwise=FALSE,allowmean = TRUE)
# modelo_automatico
# tictoc::toc()
ts_train_PIB <- window(PIB3TS,end = c(2020,1))
ts_test_PIB <- window(PIB3TS, start=c(2020,2), end=c(2023,4))
modelo_ajustado<-forecast::Arima(ts_train_PIB,order = c(0,1,0),lambda = LambdaPIB,include.constant = FALSE) ## ajustar según lo que digan las funciones de arriba
summary(modelo_ajustado)
coeftest(modelo_ajustado)
modelo_ajustado<-forecast::Arima(ts_train_PIB,order = c(0,1,0),lambda = LambdaPIB,include.constant = TRUE) ## ajustar según lo que digan las funciones de arriba
coeftest(modelo_ajustado)
#Residuales
residualesPIB=modelo_ajustado$residuals
###Estadisticas CUSUM
resPIB=residualesPIB
cumPIB=cumsum(resPIB)/sd(resPIB)
NPIB=length(resPIB)
cumqPIB=cumsum(resPIB^2)/sum(resPIB^2)
AfPIB=0.948 ###Cuantil del 95% para la estadistica cusum (valor común usado)
coPIB=0.14422####Valor del cuantil aproximado para cusumsq para n/2 (valor común usado)
LSPIB=AfPIB*sqrt(NPIB)+2*AfPIB*c(1:length(resPIB))/sqrt(NPIB)
LIPIB=-LSPIB
LQSPIB=coPIB+(1:length(resPIB))/NPIB
LQIPIB=-coPIB+(1:length(resPIB))/NPIB
hist(residualesPIB,main = "Histograma de Residuales")
plot(cumPIB,type="l",ylim=c(min(LIPIB),max(LSPIB)),xlab="t",ylab="",main="CUSUM")
lines(LSPIB,type="S",col="red")
lines(LIPIB,type="S",col="red")
plot(cumqPIB,type="l",xlab="t",ylab="",main="CUSUMSQ")
lines(LQSPIB,type="S",col="red")
lines(LQIPIB,type="S",col="red")
h=1
lseriexd=length(PIB3TS)
ntrainxd=length(ts_train_PIB)
trainxd=window(PIB3TS,end=c(2020,1))
testxd=window(PIB3TS,start=c(2020,2))
ntestXD=length(ts_test_PIB)
fcmatxd=matrix(0,nrow=ntestXD,ncol=h)
for(i in 1:ntestXD){
x=window(PIB3TS,end=c(2020,1+(i-1)))
refitxd=forecast::Arima(x,order = c(0,1,0),lambda = LambdaPIB,include.constant = TRUE)
fcmatxd[i,]=testxd[i]-forecast::forecast(refitxd,h=h)$mean
}
test_graf <- data.frame(Tiempo = time(testxd),Valor_real = as.numeric(testxd),Valor_prono = as.numeric(testxd) - as.vector(fcmatxd))
MSE_PIB <- data.frame(
Modelo = c("ARIMA", "Suavizamiento exponencial", "Árboles", "Red multicapa", "Red GRU"),
MSE = c(147264114, 147644997, 6141964443, 227726100, 15228127492)
)
ggplot(test_graf, aes(x = Tiempo)) +
geom_line(aes(y = Valor_real, color = "Serie Real"), size = 1) +
geom_line(aes(y = Valor_prono, color = "Pronóstico"), linetype = "dashed", size = 1) +
scale_color_manual(values = c("Serie Real" = "blue", "Pronóstico" = "red")) +
labs(title = "Comparación de la Serie de Tiempo Real y el Pronóstico",
x = "Tiempo",
y = "Valor",
color = "Leyenda") + theme_minimal()
source(paste0(Ruta,"/ui.R"))
source(paste0(Ruta,"/server.R"))
shinyApp(ui=ui,server = server)
runApp()
runApp()
