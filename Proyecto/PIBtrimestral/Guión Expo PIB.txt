---------------------------------------------------------------------------------------------------------------------------------------
------------------------------------Descripción serie del PIB trimestral en Colombia------------------------------------------------
---------------------------------------------------------------------------------------------------------------------------------------

Una vez presentada la serie del desempleo, a continuación el día les presentaremos el análisis hecho sobre el PIB en Colombia desde enero de 2005 
hasta diciembre de 2023, tasa medida trimestralmente.

-----------------Primer gráfico de la serie-------------------

En este primer gráfico podemos observar el comportamiento del PIB en el periodo indicado anteriormente. En un primer vistazo podemos
observar este valle correspondiente a la pandemia, dándose el punto mínimo en abril de 2020. Antes de la pandemia, se observa que el PIB tiene una 
tendencia creciente. La disminución presentada en la pandemia generó una baja significativa, la cual será referenciada al momento de exponer cada uno
de los modelos. Sin embargo, después del valle presentado en abril 2020, observamos que el PIB trata de recuperarse nuevamente, respetando la 
tendencia que mantenía hasta la pandemia.

Revisando más detalladamente, la serie no aparenta tener un patrón cíclico por cada trimestre, a comparación de la serie del desempleo, sin embargo, 
mas adelante comprobaremos si se presenta algún indicio de estacionalidad en la serie.

-------------Primer gráfico de autocorrelación---------------

Este es un primer gráfico de autocorrelación, sin embargo, no es válido puesto que nuestra serie de tiempo no tiene un comportamiento 
estacionario todavía.

---------------Transformación de Box-Cox---------------------

A continuación, vamos a comprobar si vale la pena realizar una transformación de los datos, para ello, vamos a hallar el valor de lambda que nos 
permite dar dicha conclusión. Tal y como pueden observar el valor de lambda es cercano a 1, así como el valor de 0 se encuentra incluido en el 
intervalo de confianza. Por lo que no va a ser necesario realizar una transformación de los datos.

--------------------Extracción de tendencia-------------------------

Empezaremos a retirar la tendencia de nuestra serie, implementamos 4 métodos, extracción por un modelo de regresión lineal simple, modelo
no paramétrico, diferencia ordinaria y promedios móviles. 

El modelo lineal no fue adecuado ya que este no captura el comportamiento de la pandemia, la serie resultante no oscila alrededor de un solo valor.
Esto lo pueden observar en el siguiente gráfico. Si bien está oscilando al 0, el dato atípico de la pandemia perjudica el modelo lineal, conllevando
a un sobreajuste. 

El modelo no paramétrico a pesar de que sí logra capturar este comportamiento, lo hace por medio del sobreajuste.
Con la diferencia ordinaria obtenemos una serie que, al igual que la anterior, parece oscilar alrededor del cero, a pesar de que perdemos un dato
(Q1 de 2005), estamos en el mismo escenario que en el modelo lineal.
Finalmente, con los promedios móviles también obtenemos una serie que oscila alrededor del cero, no obstante, se pierden bastantes datos y la 
cantidad que tiene esta serie es muy poca. En total tenemos 76 trimestres, por lo que consideramos no utilizarlo.

Si bien se muestra la extracción de tendencia, tanto por modelo lineal, como por diferencia ordinaria, los modelos que se expondrán a continuación 
se manejarán mediante los datos originales.

Realizando nuevamente los gráficos de autocorrelación no se encuentra un patrón de estacionalidad. Pero, hay algo interesante en el ACF de la 
extracción por modelo lineal, lo cual es que los 4 primeros retardos se ubican afuera de la brecha azul. Este dato es de suma utilidad, ya que mas 
adelante, en modelamiento de árboles, vamos a utilizar esos 4 primeros retardo para modelar la serie en ese tema.

----------------Explorando relaciones lineales--------------------

Recordemos que estamos trabajando con la serie cuya tendencia fue extraída por diferencia ordinaria, estos gráficos de dispersión entre los 
retardos a primer vistazo no evidencian una relación lineal fuerte, el retardo 4 es el que muestra una relación lineal mas alto, con un valor del 
coeficiente de 0,2

-------------------------Detección de estacionalidad---------------------

Aunque no se hayan considerado las extracciones de tendencia, para efectos de este trabajo, se mostrará la siguiente información, asumiendo que se 
hubiese elegido la diferencia ordinaria. Tal y como pueden observar, el mapa de calor indica grados de color azul muy similares. Exceptuando la 
pandemia, la cual toma un color blanco. Por lo que esto nos da un indicio de que no hay diferencias significativas entre los trimestres de cada año.
Asimismo, el gráfico de las subseries confirma este hecho, al ver que la media de cada trimestre es muy similar a la de los demás. Finalmente, si lo 
queremos analizar vía Boxplot, se puede visualizar que apenas las cajas de cada trimestre sobrepasan el 0, con medias similares. Finalmente, en el 
gráfico de estimaciones vía kernel se observa que las densidades por cada trimestre se mantienen en el mismo lado, de hecho, bastante cercanos a 0. 
Por lo que todo esto es prueba suficiente para demostrar que la serie no presenta estacionalidad, sin embargo, vamos a ver que información nos 
arroja el periodograma, para saber cómo manejamos el tema de la estacionalidad.

--------------------Periodo de la serie--------------------------

El periodograma concluye que el periodo es 4, sin embargo vemos que los picos mas altos se encuentran oscilando entre 0,2 y 0,3. Sabemos que la 
serie es trimestral, sin embargo, si la serie fuese estacional, no debiera presentar picos tan altos en numerosos valores. Por lo que, sumado a lo 
dicho en la detección de estacionalidad, se concluye que la serie del PIB no la presenta, por lo tanto, no vale la pena realizar una extracción de 
la misma.

------------------------Extracción de la estacionalidad--------------------------

Tal y como se comentó, la serie no presenta estacionalidad, sin embargo, algunos se pueden preguntar el por qué no utilizamos transformaciones vía 
componentes de Fourier o con variables Dummys. Esto se explica de la siguiente forma: estas transformaciones se utilizan si la serie presenta un 
comportamiento sinosoidal, lo cual se explica que la serie presenta un patrón cíclico; patrón que no presenta la serie del PIB en este caso, pero
 si la presentaba la serie del desempleo.

--------------------------------Suavizamiento exponencial------------------------------

El suavizamiento exponencial es un modelo que contiene 3 parámetros, dos relacionados a la estimación de la componente de tendencia, y el 
tercero a la componente de estacionalidad. El siguiente modelo tendrá únicamente las componentes relacionadas a la tendencia, las cuales son alfa y 
beta, de hecho, el modelo tendrá un valor de gamma de 0, para no tener inconvenientes con temas de estacionalidad que no vienen al caso. Por lo 
tanto, para evaluar la capacidad predictiva del modelo, utilizando la predicción a un paso, emplearemos el 80% de la serie como conjunto de 
entrenamiento y el 20% restante como prueba. Es decir, el periodo de entrenamiento corresponde a los primeros 61 trimestres, los cuales corresponden
a enero de 2005 hasta abril de 2020, por otro lado, el periodo de prueba corresponde a los últimos 15 trimestres, que van desde mayo de 2020 hasta 
diciembre de 2023. Recordemos que trabajaremos la serie original.
	

El primer paso es encontrar las estimaciones de los parámetros utilizando el conjunto de entrenamiento. Obtenemos una estimación de la componente
de nivel alpha de 1, de pendiente beta igual a 0.05827, de estacionalidad gamma igual a 0. Mediante suavizamiento exponencial, se observa que la 
serie respeta la tendencia creciente del PIB, omitiendo el periodo de pandemia, dejando un ECM de 212455066 (Ojo, este ECM es grande ya que estamos 
utilizando la escala original, la cual es de miles de millones de pesos).

Posterior a esto hacemos el rolling manualmente, nuestro horizonte de pronóstico es igual a 1, recordemos que estamos evaluando la predicción un
paso adelante, modificaremos nuestra ventana en cada iteración, añadiendo un trimestre en cada iteración, ajustamos el modelo con los parámetros
calculados en entrenamiento y realizamos el pronóstico. Por último, calculamos el error cuadrático medio, el cual nos da 1007600296. 

En este gráfico comparamos los pronósticos con la verdadera tasa de desempleo en este periodo. Obteniendo resultados que se dejan llevar por el
bajón de la pandemia, pero respetando el comportamiento creciente.

Por último está la implementación del Rolling utilizando funciones, mas como un apartado informativo.


---------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------Aprendizaje automático---------------------------------------------------
---------------------------------------------------------------------------------------------------------------------------------------

------------------------------------Árboles-----------------------------------------

Introducción a árboles

Para esta parte de árboles de decisión, solo se realizará el modelo mediante el uso de lo datos originales. Creamos los inputs y outputs, 
por lo que tendremos un dataframe que contiene los 4 primeros retardos y como output el tiempo t, o sea, haremos la predicción
un paso adelante.

--- División de los datos 

Dividimos los datos en entrenamiento, validación y prueba, teniendo como porcentajes un 70% de los datos para entrenamiento, el siguiente 18% de 
datos para validación y el 12% restante de los datos para prueba. Donde 51 datos son de entrenamiento, 12 datos son de validación y 9 son los datos de testeo

--- Creación del árbol con la serie original

Primero creamos un árbol sin especificar la profundidad, luego exploramos distintas profundidades, en esta iteración la mejor profundidad es 
5, por lo que procedemos a crear el árbol juntando entrenamiento y validación con esta profundidad. Si bien, las profundidades siguientes muestran el mismo ECM que
la profundidad 5, se escoge esta, ya que hasta este grado de profundidad, se alcanza a tomar la totalidad de los datos.

--- Gráfico predicciones VS verdaderos valores

Vemos que se logra esbozar una línea recta para el caso del conjunto de entrenamiento, sin embargo para el conjunto de prueba no sucede esto y las
predicciones parecen muy dispersas. Se pueden ver indicios de que para algunos valores el modelo subestima mas la serie, además, los valores de testeo, se mantienen muy dispersos.
Ya con el gráfico completo, se puede visualizar un sobreajuste para los datos de entrenamiento y validación. Sin embargo, como la validación toma el periodo de pandemia, al momento
de predecir los datos de testeo, se ve que el modelo toma una postura muy conservadora al predecir una recta constante. El modelo ni se esfuerza en predecir el comportamiento del PIB.

-----------------------------------Redes multicapa----------------------------------

Para este modelamiento, en la creación de los inputs, se probaron varios casos. Primero intentamos modelar la serie utilizando la red de una capa, luego se ajustará a una red multicapa y,
finalmente, se mostrarán los mejores modelos; explicando en cada uno los gráficos de las predicciones y de los verdaderos valores.

--- Red neuronal con una sola capa

Para este primer acercamiento a las redes neuronales multicapa, primero ajustamos redes neuronales de una sola capa para ver su comportamiento. Esto
se hizo para la función de activación lineal. Para la cantidad de capas, en este caso sólo usaremos una capa
oculta de 64 nodos. Como métrica seguiremos utilizando el ECM. Se usará el optimizador Adam y 50 épocas junto a un tamaño de lote = 1, por lo que
tendremos 51/1 lotes. El tamaño de los lotes se determina en 1, dado que la serie original no cuenta con la cantidad suficiente de datos para agrupar.

--- Modelo de una capa, función lineal

Primero tenemos un gráfico del comportamiento de la pérdida cuadrática en validación y en entrenamiento a través de las épocas. En este caso, la pérdida en 
los datos de testeo genera una brecha bastante grande respecto a la de los datos de entrenamiento. Por lo tanto, el modelo es pésimo para poder predecir el comportamiento
del PIB. Esto también se justifica en su ECM, donde el valor es bastante alto, a comparación del obtenido por suavizamiento exponencial (51583983616). Así como en su predicción
donde no se esfuerza en predecir la serie.

--- Red neuronal con múltiples capas

En la siguiente red se contará con tres capas ocultas, de 64, 32 y 16 nodos respectivamente. En esta red se utilizarán funciones de activación lineal y Relu.
Para la estimación de hiperparámetros, el número de capas y la cantidad de nodos se mantuvo constante. Se realizó exactamente el mismo procedimiento que con redes de una sola capa
donde mantenemos 50 épocas de tamaño de lote 1.


--- Interpretación de gráficos

En este gráfico del comportamiento de la pérdida en el conjunto de entrenamiento y validación, vemos que el comportamiento de esta red trata de acercarse en el valor de sus pérdidas
llegando a 0. El ECM del conjunto de prueba para esta red recurrente fue de 3423324416, una mejora 
considerable respecto a la primer red neuronal utilizando función lineal, siendo menos de la mitad del ECM de esa primera red. 
En el gráfico se observa que las predicciones sobreestiman los valores del PIB, aunque la pandemia no impacta en gran medida, se mantiene una gran brecha entre las predicciones y los datos reales.

--- Búsqueda de hiperparámetros utilizando Grid Search

Para terminar esta parte, se utilizó Gird Search para buscar los hiperparámetros. Para esta búsqueda se hicieron 20 épocas, con el tamaño de lote por defecto que es 32, y probando entre
funciones de activación relu y tangente hiperbólico, número de capas 1 o 2 y cantidad de nodos 32 o 64 y la capa de salida con función de activación
lineal. Tal y como se utilizó en el índice de desempleo.

Luego de esto se muestran los 10 mejores modelos arrojados en este caso. Entonces, se llamó al mejor modelo de esta búsqueda, teniendo un ECM de 53415380000, lo cual es un ECM bastante 
grande y esto ya nos da como referencia que la capacidad predictiva del modelo es muy pobre. De hecho, al interpretar el gráfico de valores reales Vs predicciones se puede notar que el mejor modelo no se esfuerza en predecir los valores del PIB, generando esa pérdida cuadrática bastante grande.

-----------------------------------Redes recurrentes--------------------------------

Utilizamos tres tipos de redes neuronales recurrentes, una normal, una GRU y una LSTM. Asimismo, al igual que en modelamientos anteriores, utilizamos el 80% de los datos para el entrenamiento y el 20% restante para probar la capacidad predictiva. No requerimos conjunto de validación ya que los hiperparámetros se calcularon mediante validación cruzada.

Estandarizamos nuestra serie de tiempo y creamos los insumos para nuestras redes, utilizamos los 4 retardos como covariables. Teniendo así
56 datos para entrenamiento y 12 para prueba.

Se modeló el PIB utilizando únicamente los 4 retardos como covariables. Definimos 100 épocas, encontramos los hiperparámetros y entrenamos la red, 
para finalmente encontrar el error cuadrático medio.
Obteniendo así 0.714201 para la red normal, 3.2635 para la GRU y 5.1483 para la LSTM, recordemos que estos no son los verdaderos errores cuadráticos
medios, ya que fueron calculados con los pronósticos hechos para el PIB estandarizad0. Más adelante hallaremos los verdaderos MSE.

Este primer gráfico muestra el comportamiento de la red en el conjunto de entrenamiento, y este segundo el comportamiento en el conjunto de prueba,
podemos ver que la red RNN (línea azul) se acerca más al valor del PIB; sin embargo, la predicción es conservadora y no se atreve a realizar predicciones aparte de una línea recta; mientras que el GRU y el LSTM predicen de forma deficiente el comportamiento del PIB

Por último, compararemos la verdadera tasa de desempleo con los pronósticos reescalados en los conjuntos de prueba, además de los verdaderos MSE.
El modelo que mejor MSE tiene, ya con los datos originales y pronósticos reescalados sigue siendo la red RNN, aunque el MSE en comparación de los otros es el mas bajo (1697414571.7),
solo se mantiene una línea recta, subestimando los valores reales del PIB. Mientras que GRU y LSTM se mantienen como los modelos mas deficientes.