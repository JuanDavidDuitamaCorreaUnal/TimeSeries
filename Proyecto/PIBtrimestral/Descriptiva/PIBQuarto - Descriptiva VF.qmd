---
title: "PIBQuarto"
format: html
editor: visual
lang: es
---

El siguiente trabajo abarca todas las metodologías vistas en el semestre 2024-1 de la asignatura Series de Tiempo Univariadas, utilizando la medición trimestral del PIB en Colombia a precios constantes (calculando el agregado a partir de la suma de las actividades económicas de Colombia), a partir del primer trimestre de 2005, hasta el último trimestre del 2023.

## Integrantes

-   Ander Cristancho
-   Anderson Guarin
-   Juan David Duitama

## Librerías utilizadas

```{r}
#| messages: FALSE
#| warning: FALSE

lista_librerías <- c("readxl","tidyr","tibble","tidyverse","lubridate","timetk", "zoo","tsibble","forecast","MASS","VGAM","car","feasts","fable","astsa","nonlinearTseries","greybox","dplyr","plotly","broom","TSstudio","reticulate","TSA","lmtest","tseries","rstudioapi","urca","uroot","fUnitRoots","tsoutliers")

no_installs <- lista_librerías[!lista_librerías %in% installed.packages()]

if(length(no_installs) > 0) {
  cat("Los siguientes paquetes no están instalados :\n")
  cat(no_installs, sep = "\n")
  install.packages(no_installs)
} else {
  cat("Todos los paquetes están instalados. \n")
}

sapply(lista_librerías, require, character=TRUE)
```

## Importación de datos

```{r}
directorio <- dirname(rstudioapi::getActiveDocumentContext()$path)
PIB3 <- read_excel(paste0(directorio,"/PIB.xlsx"), range = "AS18:AS93", col_names = FALSE)
```

## Visualización de datos

```{r}
PIB3TS <- ts(PIB3, start = c(2005, 1), end = c(2023, 4), frequency = 4)
#Convirtiendo los datos originales en objeto serie de tiempo(ts)
plot_ly( x = time(PIB3TS), y = PIB3TS, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB Trimestral en Colombia',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))

```

La conclusión inicial con este primer gráfico es que se observa la tendencia creciente del PIB, se presentó una caída súbita a partir del año 2020, ya es sabido lo que ocurrió en ese periodo. Una vez llegado el tercer trimestre de 2021, el PIB consiguió seguir la tendencia creciente que se tenía desde antes de la pandemia.

## Autocorrelación

A continuación, se presenta un primer gráfico de la autocorrelación, recordemos que éste no es válido, hasta que retiremos la tendencia y la estacionalidad.

```{r}
acf(PIB3TS,lag.max = length(PIB3TS))
```

## Análisis descriptivo

Como ya mencionamos anteriormente, el primer componente que se puede identificar en la serie de tiempo es la tendencia creciente del PIB, aparenta haber un ciclo en el que se tienen años con PIB con tendencia a aumentar. Se puede observar esto desde 2005 hasta alrededor del segundo trimestre de 2008, luego desciende, hasta empezar a crecer de nuevo, para empezar a decrecer en 2012 y crecer nuevamente en 2013. Finalmente, se presenta la caída de pandemia, de la cual se ha venido recuperando la tendencia creciente hasta el final de la serie.

### Estabilización de la Varianza (Tranformación Box-Cox)

Primero se recurre a realizar la estabilización de la varianza de la serie, a través de la **Transformación Box-Cox**.

```{r}
LambdaPIB<-BoxCox.lambda(PIB3TS, method ="loglik", lower = -3, upper = 3)#Encontrando el valor de Lambda
LambdaPIB
```

El $\lambda$ resultante es cercano a 1, por lo que no será necesario realizar una transformación sobre los datos.

```{r}
MASS::boxcox(lm(PIB3TS ~ 1),seq(-3, 3, length = 50))
```

Con el Boxcox, se confirma que $\lambda$ tiene un valor cercano a 1, pero que abarca el 0 en su intervalo de confianza.

### Extracción de la tendencia

#### Estimación mediante un modelo lineal

A continuación, se realiza un modelo de regresión lineal simple utilizando como variable regresora el tiempo, y como variable de estudio, el PIB trimestral.

```{r}
summary(fitLM <- lm(PIB3TS~time(PIB3TS), na.action=NULL))#Creando un modelo de regresión lineal
plot(PIB3TS, ylab="PIB trimestral en Colombia",xlab="Trimestre") 
abline(fitLM,col = "red")

```

Haciendo una revisión meramente visual, el modelo lineal resultante logra capturar el comportamiento creciente del PIB trimestral, ignorando el suceso ocurrido en 2020 claramente. La serie resultante de extraer esta tendencia lineal es la siguiente.

```{r}
PIB3NoLM=PIB3TS-predict(fitLM)#Eliminando la tendencia
plot_ly( x = time(PIB3NoLM), y = PIB3NoLM, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB trimestral en Colombia con tendencia lineal extraída',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

Al realizar la extracción respectiva, la serie resultante no es adecuada para continuar con el análisis, puesto que el valle resultante de la extracción en años de pandemia perjudica los próximos procedimientos. Lo cual provocaría que al realizar predicciones bajo el modelo lineal, éstas sean subajustadas.

#### Diferencia ordinaria

```{r}
DiferenciaOrd<-diff(PIB3TS)
plot_ly( x = time(DiferenciaOrd), y = DiferenciaOrd, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB sin tendencia(Diferencia Ordinaria, lag=1)',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

Las conclusiones al extraer la tendencia, mediante diferencia ordinaria, mantienen el mismo punto que la extracción mediante tendencia lineal. Por lo tanto, en algunos de los apartados trabajaremos con los datos originales.

#### Comparando las funciones de autocorrelación de las series sin tendencia

```{r}
acf(PIB3TS,lag.max = length(PIB3TS))

par(mfrow = c(1, 1))
acf(PIB3NoLM,lag.max =length(PIB3NoLM),main="Autocorrelación serie sin tendencia lineal")
acf(DiferenciaOrd,lag.max =length(DiferenciaOrd),main="Autocorrelación serie sin tendencia\npor diferencia ordinaria")
```

### Explorando relaciones no lineales

#### Gráficos de retardos

El gráfico de retardos indica que hay una relación lineal con el retardo número 4 en la serie con tendencia extraída por diferencia ordinaria.

```{r}
#El gráfico de retardos se realiza con la serie con tendencia extraída

#Tendencia extraída por diferencia ordinaria
par(mar = c(3,2,3,2))
lag1.plot(DiferenciaOrd, 4,corr=T)
```

### Detección de estacionalidad

Un primer gráfico propuesto para la detección de la estacionalidad de forma visual es el siguiente, recordemos que está siendo aplicado en la serie con la tendencia extraída.

```{r}
#Tendencia extraída por diferencia ordinaria
TSstudio::ts_heatmap(DiferenciaOrd,title = "Mapa de Calor - PIB en Colombia(Diferencia Ordinaria)")
```

```{r}
monthplot(DiferenciaOrd,main="Subseries(Diferencia Ordinaria)")
```

Otra alternativa es utilizar los gráficos de cajas

```{r}
indice1=as.Date(as.yearmon(tk_index(PIB3TS)))#Convirtiendo en fecha el indice del PIB, deja como primero de enero cada fecha
indice1.1=yearmon(as.yearmon(tk_index(PIB3TS)))

## Haciendo el objeto tsibble
df=data.frame(Fecha=indice1,PIB=as.matrix(PIB3TS))
colnames(df)[2]<-"PIB"
PIB3TSibble=as_tsibble(df)
## Haciendo el objeto tsibble
df=data.frame(Fecha=indice1,PIB=as.matrix(PIB3TS))
colnames(df)[2]<-"PIB"
PIB3TSibble=as_tsibble(df)
```

```{r}
PIB3TSibble <- PIB3TSibble %>%
  mutate(index = as.Date(Fecha))
PIB3TSibble<-PIB3TSibble%>%mutate(Diferencia=PIB-lag(PIB))
PIB3TSibble %>%
  na.omit() %>%
  plot_seasonal_diagnostics(.date_var = index, .value = Diferencia, .feature_set = c("quarter"), .geom = "boxplot")
```

Finalmente, un gráfico con las estimaciones de las densidades.

```{r}
ggplot(PIB3TSibble %>%na.omit()|>
    mutate(
        Trimestre = str_c("Trimestre ", as.character(lubridate::quarter(index)))
    ), aes(x = Diferencia)) +
      geom_density(aes(fill = Trimestre)) +
      ggtitle("LosPass - Estimación de la densidad vía Kernel por trimestre") +
      facet_grid(rows = vars(as.factor(Trimestre)))
```

#### Encontrando el periodo de la serie

```{r}
#Diferencia ordinaria
PeriodgramadTra=spectrum(as.numeric(DiferenciaOrd),log='no')
ubicacion=which.max(PeriodgramadTra$spec)

sprintf("El valor de la frecuencia donde se máximiza el periodograma para la serie con tendencia extraída por diferencia ordinaria es: %s",PeriodgramadTra$freq[ubicacion])

sprintf("El periodo correspondiente es aproximadamente: %s",1/PeriodgramadTra$freq[ubicacion])
```

De acuerdo a la información reportada en el gráfico de periodograma, no es necesario modelar la estacionalidad.

## Suavizamiento Exponencial

El suavizamiento exponencial es un modelo que contiene 3 parámetros, dos relacionados a la estimación de la componente de tendencia, y el tercero a la componente de estacionalidad. Teniendo en cuenta que para este conjunto de datos no se requiere modelar la estacionalidad, solo se tendrán en cuenta los parámetros correspondientes a la compente de tendencia.

```{=tex}
\begin{align*}
a_t & = \alpha(x_t-s_{t-p}) + (1-\alpha)(a_{t-1}+b_{t-1}) \\
b_t & = \beta(a_t-a_{t-1}) + (1-\beta)b_{t-1} \\
\end{align*}
```
El siguiente modelo se manejará con los datos originales, por lo tanto, para evaluar la capacidad predictiva del modelo, utilizando la predicción a un paso, emplearemos el 80% de la serie como conjunto de entrenamiento y el 20% restante como prueba. Es decir, el periodo de entrenamiento corresponde a los primeros 61 trimestres, es decir, de enero de 2005 hasta marzo de 2020, por otro lado, el periodo de prueba corresponde a abril de 2020 hasta diciembre de 2023.

```{r}
Train=ts(PIB3TS[1:61], start = c(2005, 1),frequency = 4) 
Test=ts(PIB3TS[62:76],start=c(2020,2),frequency = 4) 
```

## Rolling

##### Rolling manual

```{r Rolling 1}
h=1  
lserie=length(PIB3TS) 
ntrain=trunc(length(PIB3TS)*0.80)+1 ##% del datos en el conjunto de entrenamiento es del 80%. 
ntrain 
time(PIB3TS) 
time(PIB3TS)[ntrain]###Me entrega la ultima fecha de la posición ntrain #Partiendo la serie en entrenamiento y test 
train=window(PIB3TS,end=time(PIB3TS)[ntrain]) 
test=window(PIB3TS,start=time(PIB3TS)[ntrain]+1/4) ##1/4 porque es la fracción que corresponde a un trimestre 
length(train) 
ntest=length(test) 
ntest ##Me define el valor de origins, o de ventanas de rolling. 
lserie ### Comparar los valores 
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante ### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos. 
verval=cbind(test[1:ntest]) # Predicción un paso adelante
####Ajuste del modelo con los datos de entrenamiento 
HWAP_train=stats::HoltWinters(train,gamma = 0) 
HWAP_train$alpha 
HWAP_train$beta ###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores. # por ejemplo como sigue: 
require(utils) 
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1)) 
colnames(suav_inputs)<-c("alpha","beta") 
suav_inputs_tbl=tibble::as_tibble(suav_inputs) 
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta) ##Grilla de Valores 
####Se crean las ventanas de rolling y se obtiene los h-pronósticos para cada ventana(hay ntest posibles ventanas) 
for(i in 1:(ntest)){x=window(PIB3TS,end=time(PIB3TS)[ntrain]+(i-1)/4)   
print(length(x))   
refit=stats::HoltWinters(x,gamma=0,alpha=HWAP_train$alpha,bet=HWAP_train$beta)     
  fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) } 
fchstepahe
errores_pred=verval -fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario. 
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM). 
RECM=sqrt(ECM) ##Se le saca raíz  
#RECM ##se lee: Primera fila RECM 1-paso adelante y así sucesivamente. 
ECM
```

```{r}
plot_ly(x = time(test), y = test, type = 'scatter', mode = 'lines', color = I("red"), name = "PIB") %>%   
  add_trace(y = fchstepahe, mode = 'lines', line = list(color = 'blue'), name = "Predicciones") %>%   
  layout(title = 'PIB vs Predicciones (Abril 2020-Diciembre 2023)',          xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

##### Rolling usando la función

```{r rolling 2}
library(forecast) 
library(greybox) 
HWAP_train=stats::HoltWinters(train,gamma=0)   
h=1 
ourCallETS <- "forecast::forecast(stats::HoltWinters(x=data,alpha=HWAP_train$alpha,beta=HWAP_train$beta,gamma=0),h=h)" ###Note que x=data es solo un argumento indeterminado. 
ourValueETS <- c("mean","lower","upper") 
origins=ntest   ##número de rolling windows 
Valoresretornados1 <- ro(PIB3TS, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE) 
t(Valoresretornados1$holdout)## Permiten verificar los verdaderos valores h-pasos adelante.  
t(Valoresretornados1$mean) 
apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE) ### Se calcula el error cuadrático medio de predicción
```
```{r}
#'c': Se ajusta una constante (serie estacionaria alrededor de una media constante).
#'ct': Se ajusta una constante y una tendencia lineal (serie estacionaria alrededor de una tendencia lineal).
#'nc': No se ajusta ni constante ni tendencia (serie estacionaria sin media constante ni tendencia).
#lremesas porque tocó hacer transformación boxcox
#Prueba Dickey-Fuller
#Hipótesis nula (H0): La serie tiene una raíz unitaria (no es estacionaria).
#Hipótesis alternativa (H1): La serie no tiene una raíz unitaria (es estacionaria).
fUnitRoots::adfTest(PIB3TS,lags = 4,type='nc')
#P-valor 0.78, lo que indica presencia de raíz unitaria, por lo que toca hacer diferenciación

dif_PIB <- diff(PIB3TS)
#El número de retardos debe cambiar en cada transformación o dejamos siempre los del original
fUnitRoots::adfTest(dif_PIB,lags = 4,type='nc')
#p-valor 0.01, con la transformación la serie ya es estacionaria
```

```{r}
modelo_automatico<-auto.arima(dif_PIB,d=0,D=0,max.p=5,max.q=5,start.p=0, start.q=0,seasonal=FALSE,max.order=10,stationary=TRUE,ic="aic",stepwise=FALSE,allowmean = TRUE)
modelo_automatico
```

```{r}
modelo_ajustado<-forecast::Arima(PIB3TS,order = c(0,1,3),lambda = LambdaPIB,include.constant = TRUE)
summary(modelo_ajustado)
coeftest(modelo_ajustado)
```

```{r}
#drift no es significativo así que usamos fixed; fixed(AR,MA,drift o constante), NA para estimar, 0 para no estimar
modelo_ajustado<-forecast::Arima(PIB3TS,order = c(0,1,3),lambda = LambdaPIB,include.constant = TRUE, fixed = c(0,NA,0,NA))
summary(modelo_ajustado)
coeftest(modelo_ajustado)
```

```{r}
residuales=modelo_ajustado$residuals
plot(residuales)

#plot(SDresiduales)
acf(residuales,lag.max = 48)
pacf(residuales)

#Test de normalidad
#La hipótesis nula H0 es que los datos siguen una distribución normal.
#La hipótesis alternativa H1 es que los datos no siguen una distribución normal.
jarque.bera.test(residuales)
#P-valor de 0.000000346, por lo tanto los datos no siguen una distribución normal

#Test de autocorrelación
#Lags empiricamente se calcula como la raiz cuadrada del tamaño de muestra o si hay estacionalidad, se ingresa el periodo estacional, digamos en una mensual con estacionalidad anual colocamos 12 lags
#fitdf es la cantidad de parametros estimados en el modelo ARIMA (incluyendo el fidth(constante)), en este caso solo 2.
Box.test(residuales, lag = ceiling(sqrt(length(residuales))) , type = "Ljung-Box", fitdf = 2)
#H0:Los residuos son independientes y no están autocorrelacionados (es decir, la serie temporal ajustada es adecuada).
#H1: Los residuos presentan autocorrelación, lo que sugiere que el modelo no captura toda la estructura temporal de los datos.
#P-valor 0.7482, por lo tanto los residuos son independientes y no estan autocorrelocionados

monthplot(residuales)
spectrum(residuales,spans = c(3,5)) #3 menos suavizado que 5

###Estadisticas CUSUM
res=residuales
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estadistica cusum (valor común usado)
co=0.14013####Valor del cuantil aproximado para cusumsq para n/2 (valor común usado)

LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")
#CUSUMSQ
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")                    
lines(LQI,type="S",col="red")
```

```{r}
#####Fase de Pronósticos
#h la cantidad de periodos adelante que desea pronosticar
pronosticos_PIB=forecast::forecast(modelo_ajustado,h=4,level=0.95)
plot(pronosticos_PIB)
```

```{r}
h=1
lserie=length(PIB3TS)
ntrain=trunc(length(PIB3TS)*0.8)
ntrain
time(PIB3TS)
time(PIB3TS)[ntrain]###Me entrega la ultima fecha de la posicion ntrain
train=window(PIB3TS,end=c(2019,4))
test=window(PIB3TS,start=c(2020,1))
length(train)
ntest=length(test)
ntest
fcmat=matrix(0,nrow=ntest,ncol=h)
for(i in 1:ntest)
{
  x=window(PIB3TS,end=c(2019,4)+(i-1)/4)
  print(length(x))
  refit=forecast::Arima(x,order = c(0,1,3),lambda = LambdaPIB,include.constant = TRUE, fixed = c(0,NA,0,NA))
  fcmat[i,]=test[i]-forecast(refit,h=h)$mean
}
fcmat
ECM=mean(fcmat^2)
ECM
```

```{r}
test_graf <- data.frame(Tiempo = time(test),Valor_real = as.numeric(test),Valor_prono = as.numeric(test) - as.vector(fcmat))

ggplot(test_graf, aes(x = Tiempo)) +
  geom_line(aes(y = Valor_real, color = "Serie Real"), size = 1) +
  geom_line(aes(y = Valor_prono, color = "Pronóstico"), linetype = "dashed", size = 1) +
  scale_color_manual(values = c("Serie Real" = "blue", "Pronóstico" = "red")) +
  labs(title = "Comparación de la Serie de Tiempo Real y el Pronóstico",
       x = "Tiempo",
       y = "Valor",
       color = "Leyenda") + theme_minimal()
```

## 11. Outliers
```{r}
coef=coefs2poly(modelo_ajustado)
coef
outliers=tsoutliers::locate.outliers(res,coef)
outliers
xreg = outliers.effects(outliers, length(PIB3TS))
xreg
```

```{r}
modelo_ajustado2<-forecast::Arima(PIB3TS,order = c(0,1,3), xreg = xreg,lambda = LambdaPIB,include.constant = TRUE)
#, fixed = c(NA,NA,0)
modelo_ajustado2
coeftest(modelo_ajustado2)
res_2=modelo_ajustado2$residuals
coef_2=coefs2poly(modelo_ajustado2)
outliers_2 = locate.outliers(res_2,coef_2,cval=3.5)###cval=3.5 por defecto
outliers_2
xreg_2 = outliers.effects(outliers_2, length(PIB3TS))
xreg_2
```

```{r}
xreg_final<-cbind(xreg[,1:3],xreg_2,xreg[,4:8])
xreg_final
modelo_ajustado3<-forecast::Arima(PIB3TS,order = c(0,1,3), xreg = xreg_final,lambda = LambdaPIB,include.constant = TRUE)
#, fixed = c(NA,NA,0)
modelo_ajustado3
coeftest(modelo_ajustado3)
res_3=modelo_ajustado3$residuals
coef_3=coefs2poly(modelo_ajustado3)
outliers_3 = locate.outliers(res_3,coef_3,cval=3.5)###cval=3.5 por defecto
outliers_3
```

```{r}
###Creación de las variable de intervención
pasos_adel=4
num_outliers=dim(xreg_final)[2]
regresoras_aditivos=matrix(c(rep(0,pasos_adel*(num_outliers-6))),pasos_adel,num_outliers-6)
regresoras_LS=matrix(c(rep(1,pasos_adel*(num_outliers-4))),pasos_adel,num_outliers-4)
regresoras_TC=matrix(c(rep(0,pasos_adel*(num_outliers-8))),pasos_adel,num_outliers-8)
regresoras=cbind(regresoras_aditivos,regresoras_LS,regresoras_TC)
colnames(regresoras)=colnames(xreg_final)

pronostico_out=forecast(object=modelo_ajustado3,xreg=regresoras,h=pasos_adel)
pronostico_out
plot(pronostico_out)
```