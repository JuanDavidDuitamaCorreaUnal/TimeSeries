---
title: "PIBQuarto"
format: html
editor: visual
lang: es
---

El siguiente trabajo abarca todas las metodologías vistas en el semestre 2024-1 de la asignatura Series de Tiempo Univariadas, utilizando la medición trimestral del PIB en Colombia a precios constantes (calculando el agregado a partir de la suma de las actividades económicas de Colombia), a partir del primer trimestre de 2005, hasta el último trimestre del 2023.

## Integrantes

-   Ander Cristancho
-   Anderson Guarin
-   Juan David Duitama

## Librerías utilizadas

```{r}
#| messages: FALSE
#| warning: FALSE

lista_librerías <- c("readxl","tidyr","tibble","tidyverse","lubridate","timetk", "zoo","tsibble","forecast","MASS","VGAM","car","feasts","fable","astsa","nonlinearTseries","greybox","dplyr","plotly","broom","TSstudio","reticulate","TSA","lmtest","tseries","rstudioapi","urca","uroot","fUnitRoots","tsoutliers")

no_installs <- lista_librerías[!lista_librerías %in% installed.packages()]

if(length(no_installs) > 0) {
  cat("Los siguientes paquetes no están instalados :\n")
  cat(no_installs, sep = "\n")
  install.packages(no_installs)
} else {
  cat("Todos los paquetes están instalados. \n")
}

sapply(lista_librerías, require, character=TRUE)
```

## Importación de datos

```{r}
directorio <- dirname(rstudioapi::getActiveDocumentContext()$path)
PIB3 <- read_excel(paste0(directorio,"/PIB.xlsx"), range = "AS18:AS93", col_names = FALSE)
```

## Visualización de datos

```{r}
PIB3TS <- ts(PIB3, start = c(2005, 1), end = c(2023, 4), frequency = 4)
#Convirtiendo los datos originales en objeto serie de tiempo(ts)
plot_ly( x = time(PIB3TS), y = PIB3TS, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB Trimestral en Colombia',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))

```

La conclusión inicial con este primer gráfico es que se observa la tendencia creciente del PIB, se presentó una caída súbita a partir del año 2020, ya es sabido lo que ocurrió en ese periodo. Una vez llegado el tercer trimestre de 2021, el PIB consiguió seguir la tendencia creciente que se tenía desde antes de la pandemia.

## Autocorrelación

A continuación, se presenta un primer gráfico de la autocorrelación, recordemos que éste no es válido, hasta que retiremos la tendencia y la estacionalidad.

```{r}
acf(PIB3TS,lag.max = length(PIB3TS))
```

## Análisis descriptivo

Como ya mencionamos anteriormente, el primer componente que se puede identificar en la serie de tiempo es la tendencia creciente del PIB, aparenta haber un ciclo en el que se tienen años con PIB con tendencia a aumentar. Se puede observar esto desde 2005 hasta alrededor del segundo trimestre de 2008, luego desciende, hasta empezar a crecer de nuevo, para empezar a decrecer en 2012 y crecer nuevamente en 2013. Finalmente, se presenta la caída de pandemia, de la cual se ha venido recuperando la tendencia creciente hasta el final de la serie.

### Estabilización de la Varianza (Tranformación Box-Cox)

Primero se recurre a realizar la estabilización de la varianza de la serie, a través de la **Transformación Box-Cox**.

```{r}
LambdaPIB<-BoxCox.lambda(PIB3TS, method ="loglik", lower = -3, upper = 3)#Encontrando el valor de Lambda
LambdaPIB
```

El $\lambda$ resultante es cercano a 1, por lo que no será necesario realizar una transformación sobre los datos.

```{r}
MASS::boxcox(lm(PIB3TS ~ 1),seq(-3, 3, length = 50))
```

Con el Boxcox, se confirma que $\lambda$ tiene un valor cercano a 1, pero que abarca el 0 en su intervalo de confianza.

### Estimación y Extracción de la tendencia

#### Modelo Lineal

A continuación, se realiza un modelo de regresión lineal simple utilizando como variable regresora el tiempo, y como variable de estudio, el PIB trimestral.

```{r}
summary(fitLM <- lm(PIB3TS~time(PIB3TS), na.action=NULL))#Creando un modelo de regresión lineal
plot(PIB3TS, ylab="PIB trimestral en Colombia",xlab="Trimestre") 
abline(fitLM,col = "red")
```

Haciendo una revisión meramente visual, el modelo lineal resultante logra capturar el comportamiento creciente del PIB trimestral, ignorando el suceso ocurrido en 2020 claramente. La serie resultante de extraer esta tendencia lineal es la siguiente.

```{r}
PIB3NoLM=PIB3TS-predict(fitLM)#Eliminando la tendencia
plot_ly( x = time(PIB3NoLM), y = PIB3NoLM, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB trimestral en Colombia con tendencia lineal extraída',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

Al realizar la extracción respectiva, la serie resultante no es adecuada para continuar con el análisis, puesto que el valle resultante de la extracción en años de pandemia perjudica los próximos procedimientos. Lo cual provocaría que al realizar predicciones bajo el modelo lineal, éstas sean subajustadas.

#### No Paramétrica

```{r}
# Estimación de tendencia con STL
indice1 <- as.Date(as.yearmon(tk_index(PIB3TS)))
indice1.1 <- yearmonth(as.yearmon(tk_index(PIB3TS)))
df_PIB <- data.frame(Fecha=indice1,PIB=as.matrix(PIB3TS))
colnames(df_PIB)[2]<-"PIB"

# Haciendo el objeto Tsibble
PIB_tsibble <- as_tsibble(df_PIB)
str(PIB_tsibble)

df_PIB%>%timetk::plot_time_series(Fecha, PIB,
                   .interactive = TRUE,
                   .plotly_slider = TRUE)

###Ajuste STL moviendo los parámetros
df_PIB%>%mutate(PIB_Mod=smooth_vec(PIB,span = 0.2, degree = 2))%>%
  ggplot(aes(Fecha, PIB)) +
    geom_line() +
    geom_line(aes(y = PIB_Mod), color = "red")
```

En este caso, la estimación no paramétrica gráficamente logra captar el comportamiento de la serie, incluyendo el periodo de pandemia.

Ahoa bien, vamos a ver una serie de tiempo con tendencia estimada por métodos no paramétricos extraída, con el fin de observar si la estimación no paramétrica describe mejor el comportamiento del PIB trimestral.

```{r}
# Extracción de tendencia STL
STLextra_PIB<-PIB3TS-smooth_vec(PIB3TS,span = 0.2, degree = 2)
plot_ly(x = time(STLextra_PIB), y = STLextra_PIB, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB Trimestral en Colombia con tendencia STL extraída',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

Note que la componente de error sigue teniendo un pico muy bajo en los meses en que ocurrió la pandemia. Sin embargo, si no tuviésemos en cuenta el periodo de pandemia, el modelo no paramétrico tiene componente de error muy bajos en años anteriores, lo cual es un buen indicador.

#### Diferencia ordinaria

```{r}
Dif_ord_PIB<-diff(PIB3TS)
plot_ly(x = time(Dif_ord_PIB), y = Dif_ord_PIB, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB sin tendencia(Diferencia Ordinaria, lag=1)',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

Las conclusiones al extraer la tendencia, mediante diferencia ordinaria, mantienen el mismo punto que la extracción mediante tendencia lineal. Por lo tanto, en algunos de los apartados trabajaremos con los datos originales.

#### Promedio Móvil

```{r}
PIBcomProm <- decompose(PIB3TS)
plot(PIBcomProm)
ExtraProm=PIB3TS-PIBcomProm$trend
plot_ly( x = time(ExtraProm), y = ExtraProm, type = 'scatter', mode = 'lines',color=I("red")) %>%
  layout(title = 'PIB con tendencia extraída (Promedio móvil)',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

#### Comparando las funciones de autocorrelación de las series sin tendencia

```{r}
acf(PIB3TS,lag.max = length(PIB3TS))

par(mfrow = c(2, 2))
acf(PIB3NoLM,lag.max =length(PIB3NoLM),main="Autocorrelación serie sin tendencia lineal")
acf(STLextra_PIB,lag.max =length(STLextra_PIB),main="Autocorrelación serie sin tendencia STL")
acf(Dif_ord_PIB,lag.max =length(Dif_ord_PIB),main="Autocorrelación serie sin tendencia\npor diferencia ordinaria")
acf(ExtraProm[3:74],lag.max =length(ExtraProm[3:74]),main="Autocorrelación serie sin tendencia\npor promedio móvil")
```

### Explorando relaciones no lineales

#### Gráficos de retardos

El gráfico de retardos indica que hay una relación lineal con el retardo número 4.

```{r}
#El gráfico de retardos se realiza con la serie con tendencia extraída

#Tendencia extraída por diferencia ordinaria
par(mar = c(3,2,3,2))
lag1.plot(Dif_ord_PIB, 4,corr=T)
```

### Detección de estacionalidad

Un primer gráfico propuesto para la detección de la estacionalidad de forma visual es el siguiente, recordemos que está siendo aplicado en la serie con la tendencia extraída por diferencia ordinaria.

```{r}
#Tendencia extraída por diferencia ordinaria
TSstudio::ts_heatmap(Dif_ord_PIB,title = "Mapa de Calor - PIB en Colombia(Diferencia Ordinaria)")
```

```{r}
monthplot(Dif_ord_PIB,main="Subseries(Diferencia Ordinaria)")
```

Otra alternativa es utilizar los gráficos de cajas

```{r}
PIB_tsibble <- PIB_tsibble %>%
  mutate(index = as.Date(Fecha))
PIB_tsibble<-PIB_tsibble%>%mutate(Diferencia=PIB-lag(PIB))
PIB_tsibble %>%
  na.omit() %>%
  plot_seasonal_diagnostics(.date_var = index, .value = Diferencia, .feature_set = c("quarter"), .geom = "boxplot")
```

Finalmente, un gráfico con las estimaciones de las densidades.

```{r}
ggplot(PIB_tsibble %>%na.omit()|>
    mutate(
        Trimestre = str_c("Trimestre ", as.character(lubridate::quarter(index)))
    ), aes(x = Diferencia)) +
      geom_density(aes(fill = Trimestre)) +
      ggtitle("Estimación de la densidad vía Kernel por trimestre") +
      facet_grid(rows = vars(as.factor(Trimestre)))
```

#### Encontrando el periodo de la serie

```{r}
#Diferencia ordinaria
PeriodgramadTra=spectrum(as.numeric(Dif_ord_PIB),log='no')
ubicacion=which.max(PeriodgramadTra$spec)

sprintf("El valor de la frecuencia donde se máximiza el periodograma para la serie con tendencia extraída por diferencia ordinaria es: %s",PeriodgramadTra$freq[ubicacion])

sprintf("El periodo correspondiente es aproximadamente: %s",1/PeriodgramadTra$freq[ubicacion])
```

De acuerdo a la información reportada en el gráfico de periodograma, no es necesario modelar la estacionalidad.

#### Estimación y Extracción vía componentes de Fourier y Variables Dummy

```{r}
DiferTSibl<-as_tsibble(Dif_ord_PIB)
DiferTSibl

###Explore diferentes valores de K
Modelo_serie_diff<-DiferTSibl|>model(
  `Fourier1Desempleo`=ARIMA(value~fourier(K=2)+pdq(0, 0, 0) + PDQ(0, 0, 0))#En este caso se hace con tres componentes de Fourier
  
)

real_ajustado1<-DiferTSibl%>%left_join(fitted(Modelo_serie_diff,by=index))#%>%select(-.model) 

plot_ly(x = time(Dif_ord_PIB), y = Dif_ord_PIB, type = 'scatter', mode = 'lines', color = I("red"), name = "Serie1") %>%
  add_trace(y = real_ajustado1$.fitted, mode = 'lines', line = list(color = 'blue'), name = "Ajuste Armónico") %>%
  layout(title = 'PIB Trimestral sin tendencia (Diferencia Ordinaria, lag=1)',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))

#####Ajuste Dummy

ModeloDummy<-DiferTSibl|>model(
  `DummyDesempleoDiff`=ARIMA(value~season()+pdq(0, 0, 0) + PDQ(0, 0, 0))
  
)
real_ajustado2<-DiferTSibl%>%left_join(fitted(ModeloDummy,by=index))#%>%select(-.model) 


plot_ly(x = time(Dif_ord_PIB), y = Dif_ord_PIB, type = 'scatter', mode = 'lines', color = I("red"), name = "Serie1") %>%
  add_trace(y = real_ajustado2$.fitted, mode = 'lines', line = list(color = 'blue'), name = "Ajuste Dummy") %>%
  layout(title = 'PIB Trimestral sin tendencia (Diferencia Ordinaria, lag=1)',
         xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))

#### Varios modelos al mismo tiempo

ajuste_final_models<-DiferTSibl%>%model(
 `Fourier1DesempleoDiff`=ARIMA(value~fourier(K=1)+pdq(0, 0, 0) + PDQ(0, 0, 0)),#1 componente de Fourier
 `Fourier2DesempleoDiff`=ARIMA(value~fourier(K=2)+pdq(0, 0, 0) + PDQ(0, 0, 0)),#2 componente de Fourier
`DummyDesempleoDiff`=ARIMA(value~season()+pdq(0, 0, 0) + PDQ(0, 0, 0))#Ajuste dummy
                                        )

glance(ajuste_final_models)

Modelo_serie_diff_models<-DiferTSibl%>%left_join(fitted(ajuste_final_models)|>group_by(.model)%>%
    pivot_wider(names_from = .model, values_from = .fitted))

plot_ly(x = time(Dif_ord_PIB), y = Dif_ord_PIB, type = 'scatter', mode = 'lines', color = I("red"), name = "SerieDifOrd") %>%
add_trace(y = Modelo_serie_diff_models$Fourier1DesempleoDiff, mode = 'lines', line = list(color = 'blue'), name = "Fourier1") %>%
add_trace(y = Modelo_serie_diff_models$Fourier2DesempleoDiff, mode = 'lines', line = list(color = 'green'), name = "Fourier2") %>%
add_trace(y = Modelo_serie_diff_models$DummyDesempleoDiff, mode = 'lines', line = list(color = 'purple'), name = "Dummy") %>%  
  layout(title = 'Tasa de Desempleo sin tendencia (Diferencia Ordinaria, lag=1)',
         xaxis = list(title = 'Mes', rangeslider = list(type = 'date')))
```

```{r}
plot_ly(x = time(Dif_ord_PIB), y = Dif_ord_PIB, type = 'scatter', mode = 'lines', color = I("red"), name = "SerieDifOrd") %>%
add_trace(y = Dif_ord_PIB-Modelo_serie_diff_models$Fourier1DesempleoDiff, mode = 'lines', line = list(color = 'blue'), name = "Fourier1") %>%
add_trace(y = Dif_ord_PIB-Modelo_serie_diff_models$Fourier2DesempleoDiff, mode = 'lines', line = list(color = 'green'), name = "Fourier2") %>%
add_trace(y = Dif_ord_PIB-Modelo_serie_diff_models$DummyDesempleoDiff, mode = 'lines', line = list(color = 'purple'), name = "Dummy") %>%  
  layout(title = 'Tasa de Desempleo sin tendencia y estacionalidad (Diferencia Ordinaria, lag=1)',
         xaxis = list(title = 'Mes', rangeslider = list(type = 'date')))
```

## Suavizamiento Exponencial

El suavizamiento exponencial es un modelo que contiene 3 parámetros, dos relacionados a la estimación de la componente de tendencia, y el tercero a la componente de estacionalidad. Teniendo en cuenta que para este conjunto de datos no se requiere modelar la estacionalidad, solo se tendrán en cuenta los parámetros correspondientes a la compente de tendencia.

```{=tex}
\begin{align*}
a_t & = \alpha(x_t-s_{t-p}) + (1-\alpha)(a_{t-1}+b_{t-1}) \\
b_t & = \beta(a_t-a_{t-1}) + (1-\beta)b_{t-1} \\
\end{align*}
```
El siguiente modelo se manejará con los datos originales, por lo tanto, para evaluar la capacidad predictiva del modelo, utilizando la predicción a un paso, emplearemos el 80% de la serie como conjunto de entrenamiento y el 20% restante como prueba. Es decir, el periodo de entrenamiento corresponde a los primeros 61 trimestres, es decir, de enero de 2005 hasta marzo de 2020, por otro lado, el periodo de prueba corresponde a abril de 2020 hasta diciembre de 2023.

```{r}
Train=ts(PIB3TS[1:61], start = c(2005, 1),frequency = 4) 
Test=ts(PIB3TS[62:76],start=c(2020,2),frequency = 4) 
```

## Rolling

##### Rolling manual

```{r Rolling 1}
h=1  
lserie=length(PIB3TS) 
ntrain=trunc(length(PIB3TS)*0.80)+1 ##% del datos en el conjunto de entrenamiento es del 80%. 
ntrain 
time(PIB3TS) 
time(PIB3TS)[ntrain]###Me entrega la ultima fecha de la posición ntrain #Partiendo la serie en entrenamiento y test 
train=window(PIB3TS,end=time(PIB3TS)[ntrain]) 
test=window(PIB3TS,start=time(PIB3TS)[ntrain]+1/4) ##1/4 porque es la fracción que corresponde a un trimestre 
length(train) 
ntest=length(test) 
ntest ##Me define el valor de origins, o de ventanas de rolling. 
lserie ### Comparar los valores 
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante ### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos. 
verval=cbind(test[1:ntest]) # Predicción un paso adelante
####Ajuste del modelo con los datos de entrenamiento 
HWAP_train=stats::HoltWinters(train,gamma = 0) 
HWAP_train$alpha 
HWAP_train$beta ###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores. # por ejemplo como sigue: 
require(utils) 
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1)) 
colnames(suav_inputs)<-c("alpha","beta") 
suav_inputs_tbl=tibble::as_tibble(suav_inputs) 
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta) ##Grilla de Valores 
####Se crean las ventanas de rolling y se obtiene los h-pronósticos para cada ventana(hay ntest posibles ventanas) 
for(i in 1:(ntest)){x=window(PIB3TS,end=time(PIB3TS)[ntrain]+(i-1)/4)   
print(length(x))   
refit=stats::HoltWinters(x,gamma=0,alpha=HWAP_train$alpha,bet=HWAP_train$beta)     
  fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) } 
fchstepahe
errores_pred=verval -fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario. 
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM). 
RECM=sqrt(ECM) ##Se le saca raíz  
#RECM ##se lee: Primera fila RECM 1-paso adelante y así sucesivamente. 
ECM
```

```{r}
plot_ly(x = time(test), y = test, type = 'scatter', mode = 'lines', color = I("red"), name = "PIB") %>%   
  add_trace(y = fchstepahe, mode = 'lines', line = list(color = 'blue'), name = "Predicciones") %>%   
  layout(title = 'PIB vs Predicciones (Abril 2020-Diciembre 2023)',          xaxis = list(title = 'Trimestre', rangeslider = list(type = 'date')))
```

##### Rolling usando la función

```{r rolling 2}
library(forecast) 
library(greybox) 
HWAP_train=stats::HoltWinters(train,gamma=0)   
h=1 
ourCallETS <- "forecast::forecast(stats::HoltWinters(x=data,alpha=HWAP_train$alpha,beta=HWAP_train$beta,gamma=0),h=h)" ###Note que x=data es solo un argumento indeterminado. 
ourValueETS <- c("mean","lower","upper") 
origins=ntest   ##número de rolling windows 
Valoresretornados1 <- ro(PIB3TS, h=h, origins=origins, call=ourCallETS, value=ourValueETS,ci=FALSE,co=FALSE) 
t(Valoresretornados1$holdout)## Permiten verificar los verdaderos valores h-pasos adelante.  
t(Valoresretornados1$mean) 
apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE) ### Se calcula el error cuadrático medio de predicción
```

Veamos si el error cuadrático medio haciendolo manualmente es igual a cuando utilizamos la función.

```{r}
apply((Valoresretornados1$holdout -Valoresretornados1$mean)^2,1,mean,na.rm=TRUE) == ECM
```

El error cuadrático medio de las predicciones un paso adelante tanto en el rolling manual como utilizando la función son iguales.

## ARMA, ARIMA y SARIMA

### Ajuste Modelo ARIMA

#### Prueba de Raíz Unitaria

```{r}
#'c': Se ajusta una constante (serie estacionaria alrededor de una media constante).
#'ct': Se ajusta una constante y una tendencia lineal (serie estacionaria alrededor de una tendencia lineal).
#'nc': No se ajusta ni constante ni tendencia (serie estacionaria sin media constante ni tendencia).
#lremesas porque tocó hacer transformación boxcox
#Prueba Dickey-Fuller
#Hipótesis nula (H0): La serie tiene una raíz unitaria (no es estacionaria).
#Hipótesis alternativa (H1): La serie no tiene una raíz unitaria (es estacionaria).
ar(PIB3TS)
fUnitRoots::adfTest(PIB3TS,lags = 4,type='nc')
#P-valor = 0.99, lo que indica presencia de raíz unitaria, por lo que toca hacer diferenciación

diff_PIB <- diff(PIB3TS)
#El número de retardos debe cambiar en cada transformación o dejamos siempre los del original
fUnitRoots::adfTest(diff_PIB,lags = 4,type='nc')
#p-valor = 0.01, con la transformación la serie ya es estacionaria
```

Cuando se realiza la primera prueba de raíz unitaria, nos da un valor p de 0.99, lo cual hay que hacer diferenciación. Una vez diferenciada la serie, podemosver que la sere ya es estacionaria, con un valor p de 0.01.

#### Identificación del modelo utilizando ACF y PACF

```{r}
##Autocorrelogramas
acf(diff_PIB)
acf(diff_PIB,lag.max = 10, ci.type='ma')# q=0,1, Q=0,1
pacf(diff_PIB,lag.max = 10) # p=0,1,2,...,9,10 P=0,1
#En resumen podríamos proponer max q=1, Q=1, p=10, P=1
#Cuando se diferencia 2 veces o más, en este caso dos ordinarias y una estacional, el drift se debería ignorar

diff_PIB_train <- window(diff_PIB,end = c(2020,1))
diff_PIB_test <- window(diff_PIB, start=c(2020,2), end=c(2023,4))

tictoc::tic()
modelo_automatico<-auto.arima(diff_PIB_train,d=1,D=0,max.p=0,max.q=4,max.P=4,max.Q=4,start.p=0, start.q=0,seasonal=FALSE,max.order=10,stationary=TRUE,ic="aic",stepwise=FALSE,allowmean = TRUE)
modelo_automatico
tictoc::toc()
```

Se divicen los datos en entrenamiento (80%) y prueba (20%).

#### Ajuste de Parámetros

```{r}
ts_train_PIB <- window(PIB3TS,end = c(2020,1))
ts_test_PIB <- window(PIB3TS, start=c(2020,2), end=c(2023,4))
modelo_ajustado<-forecast::Arima(ts_train_PIB,order = c(0,1,4),lambda = LambdaPIB,include.constant = FALSE) ## ajustar según lo que digan las funciones de arriba
summary(modelo_ajustado)
coeftest(modelo_ajustado)
```

#### Eliminación de Parámetros no significativos

```{r}
modelo_ajustado<-forecast::Arima(ts_train_PIB,order = c(0,1,4), lambda = LambdaPIB,include.constant = FALSE, fixed = c(NA,NA,NA,0))  ## eliminar los parametros no significativos

summary(modelo_ajustado)
coeftest(modelo_ajustado)
```

#### Análisis de Residuales

```{r}
residuales=modelo_ajustado$residuals
plot(residuales)

#plot(SDresiduales)
acf(residuales,lag.max = 10)
pacf(residuales)

#Test de normalidad
#La hipótesis nula H0 es que los datos siguen una distribución normal.
#La hipótesis alternativa H1 es que los datos no siguen una distribución normal.
jarque.bera.test(residuales)
#P-valor de 0.000000346, por lo tanto los datos no siguen una distribución normal

#Test de autocorrelación
#Lags empiricamente se calcula como la raiz cuadrada del tamaño de muestra o si hay estacionalidad, se ingresa el periodo estacional, digamos en una mensual con estacionalidad anual colocamos 12 lags
#fitdf es la cantidad de parametros estimados en el modelo ARIMA (incluyendo el fidth(constante)), en este caso solo 2.
Box.test(residuales, lag = ceiling(sqrt(length(residuales))) , type = "Ljung-Box", fitdf = 1)
#H0:Los residuos son independientes y no están autocorrelacionados (es decir, la serie temporal ajustada es adecuada).
#H1: Los residuos presentan autocorrelación, lo que sugiere que el modelo no captura toda la estructura temporal de los datos.
#P-valor 0.7482, por lo tanto los residuos son independientes y no estan autocorrelocionados

monthplot(residuales)
spectrum(residuales,spans = c(3,5)) #3 menos suavizado que 5

###Estadisticas CUSUM
res=residuales
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estadistica cusum (valor común usado)
co=0.14013####Valor del cuantil aproximado para cusumsq para n/2 (valor común usado)

LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")
#CUSUMSQ
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")                    
lines(LQI,type="S",col="red")
```

```{r}
#####Fase de Pronósticos
#h la cantidad de periodos adelante que desea pronosticar
pronosticos_PIB=forecast::forecast(modelo_ajustado,h=1,level=0.95)
plot(pronosticos_PIB)
```

#### Rolling con datos ARIMA (1,1,4)

```{r}
h=1
lserie=length(PIB3TS)
ntrain=trunc(length(PIB3TS)*0.80+1)
ntrain
time(PIB3TS)
time(PIB3TS)[ntrain]###Me entrega la ultima fecha de la posicion ntrain
train=window(PIB3TS,end=c(2020,1))
test=window(PIB3TS,start=c(2020,2))
length(train)
ntest=length(test)
ntest
fcmat=matrix(0,nrow=ntest,ncol=h)
for(i in 1:ntest)
{
  x=window(PIB3TS,end=c(2020,2)+(i-1)/4)
  print(length(x))
  refit=forecast::Arima(x,order = c(0,1,4),lambda = LambdaPIB,include.constant = FALSE, fixed = c(NA,NA,NA,0))
  fcmat[i,]=test[i]-forecast(refit,h=h)$mean
}
fcmat
ECM=mean(fcmat^2)
ECM
```

```{r}
test_graf <- data.frame(Tiempo = time(test),Valor_real = as.numeric(test),Valor_prono = as.numeric(test) - as.vector(fcmat))

ggplot(test_graf, aes(x = Tiempo)) +
  geom_line(aes(y = Valor_real, color = "Serie Real"), size = 1) +
  geom_line(aes(y = Valor_prono, color = "Pronóstico"), linetype = "dashed", size = 1) +
  scale_color_manual(values = c("Serie Real" = "blue", "Pronóstico" = "red")) +
  labs(title = "Comparación de la Serie de Tiempo Real y el Pronóstico",
       x = "Tiempo",
       y = "Valor",
       color = "Leyenda") + theme_minimal()
```



